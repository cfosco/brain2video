{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running zeroscope locally to test the properties of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.utils import export_to_video\n",
    "import shutil\n",
    "import os\n",
    "# Check gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7c445ed3c34f69a864beb440c70796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TextToVideoSDPipeline {\n",
       "  \"_class_name\": \"TextToVideoSDPipeline\",\n",
       "  \"_diffusers_version\": \"0.20.2\",\n",
       "  \"_name_or_path\": \"../zeroscope_v2_576w\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DPMSolverMultistepScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet3DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\"../zeroscope_v2_576w\", torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.enable_model_cpu_offload()\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 77, 1024])\n"
     ]
    }
   ],
   "source": [
    "text_emb1 = pipe._encode_prompt(\n",
    "        [\"a dog\",\"cat\"],\n",
    "        \"cuda:0\",\n",
    "        num_images_per_prompt=1,\n",
    "        do_classifier_free_guidance=False,\n",
    "    )\n",
    "\n",
    "text_emb2 = pipe._encode_prompt(\n",
    "        \"a dog\",\n",
    "        \"cuda:0\",\n",
    "        num_images_per_prompt=1,\n",
    "        do_classifier_free_guidance=False,\n",
    "    )\n",
    "\n",
    "print(text_emb1.shape)\n",
    "# compare tensors in first dimension\n",
    "# print(torch.allclose(text_emb1[:,1,:], text_emb1[:,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 25769803776\n",
      "Free memory: 22704619520\n",
      "Used memory: 3065184256\n"
     ]
    }
   ],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(1)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n",
    "\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c103854ca84884a9db1e3b93166e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 <class 'list'> <class 'numpy.ndarray'>\n",
      "(320, 320, 3)\n",
      "../zeroscope_test_generations/a baby is holding a hose up high and spraying water. The baby is over the lawn.mp4\n",
      "MoviePy - Building file  ../zeroscope_test_generations/a baby is holding a hose up high and spraying water. The baby is over the lawn.gif\n",
      "MoviePy - - Generating GIF frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - - File ready: ../zeroscope_test_generations/a baby is holding a hose up high and spraying water. The baby is over the lawn.gif.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "## Perform inference\n",
    "\n",
    "prompt = \"a toddler is holding a hose up high and spraying water. The baby is over the lawn\"\n",
    "video_frames = pipe(prompt, num_inference_steps=10, height=320, width=320, num_frames=24).frames\n",
    "video_path = export_to_video(video_frames)\n",
    "\n",
    "# Move video to output folder\n",
    "output_path = f'../zeroscope_test_generations/{prompt}.mp4'\n",
    "output_gif_filepath = f'../zeroscope_test_generations/{prompt}.gif'\n",
    "shutil.move(video_path, output_path)\n",
    "print(output_path)\n",
    "\n",
    "# Make gif\n",
    "from utils import vid_to_gif\n",
    "vid_to_gif(output_path, output_gif_filepath, size=256)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RAM usage when loading all BOLDMoments videos at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM usage: 23065 MB\n",
      "Videos array size: 81522.03735351562 MB\n",
      "RAM usage: 104675 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np  \n",
    "\n",
    "n_frames_to_load = 45\n",
    "size = 268\n",
    "n_videos = 1102\n",
    "\n",
    "# Show current RAM usage\n",
    "print(\"RAM usage:\", os.popen('free -t -m').readlines()[1].split()[2], \"MB\")\n",
    "\n",
    "# Make an array of random values\n",
    "videos = np.random.rand(n_videos, n_frames_to_load, 3, size, size)\n",
    "\n",
    "# videos = np.random.rand((n_videos, n_frames_to_load, 3, size, size))\n",
    "\n",
    "# DEBUG: Print memory size of videos array\n",
    "print(\"Videos array size:\", videos.nbytes/1024**2, \"MB\")\n",
    "\n",
    "# Show current RAM usage after loading videos\n",
    "print(\"RAM usage:\", os.popen('free -t -m').readlines()[1].split()[2], \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
