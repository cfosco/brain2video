{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to put all betas into individual pkl files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform NSD betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loads a pkl file with betas and stores each vector separately\n",
    "\n",
    "def nsd_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "    \n",
    "    for sub in subs:\n",
    "        # Load pickle with ids of stimuli\n",
    "        with open(f'{betas_path}/{sub}/events_imgtag-73k_id.pkl', 'rb') as f:\n",
    "            idxs = pkl.load(f)[0]\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typeb_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "            d = data['data_allvoxel']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            \n",
    "            # If savedir exists, delete all its contents\n",
    "            if os.path.exists(savedir):\n",
    "                for f in os.listdir(savedir):\n",
    "                    os.remove(os.path.join(savedir, f))\n",
    "            else:\n",
    "                os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "            for s, stim in tqdm(enumerate(d)):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{idxs[s]-1:06d}_{r}.npy' #TODO: Check if indexes match correctly here\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_betas_to_indiv_files('../data/betas_nsd', rois=['lPPA', 'rPPA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform BMD betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bmd_betas_to_indiv_files(betas_path, \n",
    "                             subs=None,\n",
    "                             rois=None):\n",
    "\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "    \n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typed_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            print(data.keys())\n",
    "\n",
    "            # d = np.concatenate([data['train_data_allvoxel'], data['test_data_allvoxel']], axis=0)\n",
    "            d_train = data['train_data_allvoxel']\n",
    "            d_test = data['test_data_allvoxel']\n",
    "            \n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d_train):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{s+1:04d}_{r}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n",
    "            for s, stim in enumerate(d_test):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{s+1+len(d_train):04d}_{r}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_betas_to_indiv_files('../data/betas_impulse', \n",
    "                     rois=['lPPA', 'rPPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform CIFTI betas to indiv files \n",
    "# (cifti betas pickles have the same format as impulse/volumetric betas)\n",
    "\n",
    "bmd_betas_to_indiv_files('../data/betas_cifti_bmd',\n",
    "                            rois=['Group41'])\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform HAD cifti betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def had_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "    \n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "\n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typeb_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "            d = data['data_allvoxel']\n",
    "            vid_names = data['stim_order']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{vid_names[s]}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_betas_to_indiv_files('../data/betas_cifti_had', \n",
    "                     rois=['Group41'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform NOD cifti Betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sub01...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub02...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub03...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub04...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub05...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub06...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub07...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub08...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub09...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(4000, 1, 13156)\n",
      "Processing sub10...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub11...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub12...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub13...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub14...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub15...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub16...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub17...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub18...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub19...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub20...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub21...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub22...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub23...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub24...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub25...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub26...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub27...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub28...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub29...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n",
      "Processing sub30...\n",
      "Processing Group41_betas_z=1.pkl...\n",
      "(1000, 1, 13156)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nod_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "    \n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "\n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            print(data['data_allvoxel'].shape) # (4000, 1, 13156)\n",
    "\n",
    "            d = data['data_allvoxel']\n",
    "            vid_names = data['stim_order']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{vid_names[s].split(\"/\")[-1][:-5]}.npy'\n",
    "                    # print(npy_name)\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n",
    "\n",
    "\n",
    "nod_betas_to_indiv_files('../data/betas_cifti_nod', \n",
    "                     rois=['Group41'],\n",
    "                    #  subs=[f'sub{sub:02d}' for sub in range(1,5)],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
