{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to put all betas into individual pkl files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform NSD betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that loads a pkl file with betas and stores each vector separately\n",
    "\n",
    "def nsd_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "    \n",
    "    for sub in subs:\n",
    "        # Load pickle with ids of stimuli\n",
    "        with open(f'{betas_path}/{sub}/events_imgtag-73k_id.pkl', 'rb') as f:\n",
    "            idxs = pkl.load(f)[0]\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typeb_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "            d = data['data_allvoxel']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            \n",
    "            # If savedir exists, delete all its contents\n",
    "            if os.path.exists(savedir):\n",
    "                for f in os.listdir(savedir):\n",
    "                    os.remove(os.path.join(savedir, f))\n",
    "            else:\n",
    "                os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "            for s, stim in tqdm(enumerate(d)):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{idxs[s]-1:06d}_{r}.npy' #TODO: Check if indexes match correctly here\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_betas_to_indiv_files('../data/betas_nsd', rois=['lPPA', 'rPPA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform BMD betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bmd_betas_to_indiv_files(betas_path, \n",
    "                             subs=None,\n",
    "                             rois=None):\n",
    "\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "    \n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typed_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            print(data.keys())\n",
    "\n",
    "            # d = np.concatenate([data['train_data_allvoxel'], data['test_data_allvoxel']], axis=0)\n",
    "            d_train = data['train_data_allvoxel']\n",
    "            d_test = data['test_data_allvoxel']\n",
    "            \n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d_train):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{s+1:04d}_{r}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n",
    "            for s, stim in enumerate(d_test):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{s+1+len(d_train):04d}_rep{r}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd_betas_to_indiv_files('../data/betas_impulse', \n",
    "                     rois=['lPPA', 'rPPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform CIFTI betas to indiv files \n",
    "# (cifti betas pickles have the same format as impulse/volumetric betas)\n",
    "\n",
    "bmd_betas_to_indiv_files('../data/betas_cifti_bmd',\n",
    "                            rois=['Group41'])\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files from 0001_0.npy to 0001_rep0.npy\n",
    "# (to match the naming convention of the other datasets)\n",
    "\n",
    "def rename_files(betas_path, \n",
    "                 subs=None,\n",
    "                 rois=None):\n",
    "    '''Renames individual npy files from 0001_0.npy to 0001_rep0.npy, to follow the new format.\n",
    "    Only run this if your individual npy files are in the old format (e.g. 0001_0.npy for BMD)'''\n",
    "\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "    \n",
    "    for sub in subs:\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'indiv_npys'))])\n",
    "        for roi in rois:\n",
    "            roi = roi+'_betas-GLMsingle_type-typed_z=1'\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi)\n",
    "            for f in os.listdir(savedir):\n",
    "                if '_rep' in f:\n",
    "                    continue\n",
    "                print(\"renaming\", os.path.join(savedir, f), 'to',  os.path.join(savedir, f[:-5]+'rep'+f[-5:]))\n",
    "                # os.rename(os.path.join(savedir, f),\n",
    "                #         os.path.join(savedir, f[:-5]+'rep'+f[-5:]))\n",
    "\n",
    "rename_files('../data/betas_cifti_bmd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform HAD cifti betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def had_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "    \n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "\n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas-GLMsingle_type-typeb_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "            d = data['data_allvoxel']\n",
    "            vid_names = data['stim_order']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{vid_names[s]}.npy'\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_betas_to_indiv_files('../data/betas_cifti_had', \n",
    "                     rois=['Group41'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform NOD cifti Betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nod_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "    \n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "\n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_betas_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            print(data['data_allvoxel'].shape) # (4000, 1, 13156)\n",
    "\n",
    "            d = data['data_allvoxel']\n",
    "            vid_names = data['stim_order']\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            for s, stim in enumerate(d):\n",
    "                for r, rep in enumerate(stim):\n",
    "                    npy_name = f'{vid_names[s].split(\"/\")[-1][:-5]}.npy'\n",
    "                    # print(npy_name)\n",
    "                    np.save(os.path.join(savedir, npy_name), rep)\n",
    "\n",
    "\n",
    "nod_betas_to_indiv_files('../data/betas_cifti_nod', \n",
    "                     rois=['Group41'],\n",
    "                    #  subs=[f'sub{sub:02d}' for sub in range(1,5)],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform CC2017 cifti Betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sub01...\n",
      "Processing Group41_estimates-TSTrialEstimates_z=1.pkl...\n",
      "Processing sub02...\n",
      "Processing Group41_estimates-TSTrialEstimates_z=1.pkl...\n",
      "Processing sub03...\n",
      "Processing Group41_estimates-TSTrialEstimates_z=1.pkl...\n"
     ]
    }
   ],
   "source": [
    "def cc2017_betas_to_indiv_files(betas_path, \n",
    "                         subs=None, \n",
    "                         rois=None):\n",
    "    \n",
    "    # Work on all subs if subs is None\n",
    "    if subs is None:\n",
    "        subs = sorted(os.listdir(betas_path))\n",
    "\n",
    "    # Loop over subjects and save npys\n",
    "    for sub in subs:\n",
    "        print(f'Processing {sub}...')\n",
    "\n",
    "        # Work on all ROIs if rois is None\n",
    "        if rois is None:\n",
    "            rois = sorted([r.split('_')[0] for r in os.listdir(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl'))])\n",
    "        \n",
    "        for roi in rois:\n",
    "            roi_pkl = roi+'_estimates-TSTrialEstimates_z=1.pkl'\n",
    "            print(f'Processing {roi_pkl}...')\n",
    "            with open(os.path.join(betas_path, sub, 'prepared_allvoxel_pkl', roi_pkl), 'rb') as f:\n",
    "                data = pkl.load(f)\n",
    "\n",
    "            savedir = os.path.join(betas_path, sub, 'indiv_npys', roi_pkl[:-4])\n",
    "\n",
    "            # Save train npys\n",
    "            rename_and_save(data['train_data_allvoxel'], data['train_stim_order'], savedir)\n",
    "\n",
    "            # Save test npys\n",
    "            rename_and_save(data['test_data_allvoxel'], data['test_stim_order'], savedir)\n",
    "\n",
    "def rename_and_save(fmri_data, vid_names, savedir):\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "    seen={}\n",
    "    for name, stim in zip(vid_names, fmri_data):\n",
    "        fixed_name = fix_seconds_format(name)\n",
    "        if fixed_name in seen:\n",
    "            seen[fixed_name] += 1\n",
    "        else:\n",
    "            seen[fixed_name] = 0\n",
    "        npy_name = f'{fixed_name}_rep{seen[fixed_name]}.npy'\n",
    "        # print('npy_name', npy_name)\n",
    "        # print('stim.shape', stim.shape)\n",
    "        # print('seen[fixed_name]', seen[fixed_name])\n",
    "        np.save(os.path.join(savedir, npy_name), stim)\n",
    "        \n",
    "\n",
    "# Fix seconds format to match the .mp4 filenames, e.g. \"-2\" -> \"-002\"\n",
    "import re\n",
    "def fix_seconds_format(s):\n",
    "    return re.sub(r'-(\\d+)', lambda m: '-%03d' % int(m.group(1)), s)\n",
    "\n",
    "\n",
    "cc2017_betas_to_indiv_files('../data/betas_cifti_cc2017', \n",
    "                     rois=['Group41'],\n",
    "                    #  subs=[f'sub{sub:02d}' for sub in range(1,5)],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
